<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RPM Detection</title>
</head>
<body>
    <h1>RPM Detection App</h1>
    <p>Click the button to start detecting the BPM and RPM from music!</p>
    <button id="startButton">Start Listening</button>

    <h2>Audio Level: <span id="audioLevel">--</span></h2>
    <h2>BPM: <span id="bpmDisplay">--</span></h2>
    <h2>RPM: <span id="rpmDisplay">--</span></h2>

    <script>
        const startButton = document.getElementById('startButton');
        const audioLevelDisplay = document.getElementById('audioLevel');
        const bpmDisplay = document.getElementById('bpmDisplay');
        const rpmDisplay = document.getElementById('rpmDisplay');
        let audioContext, analyser, dataArray, previousTime = 0, beatTimestamps = [], smoothedAmplitude = 0;
        let threshold = 0;  // Adaptive threshold for beat detection

        startButton.addEventListener('click', function() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 2048;
                    const bufferLength = analyser.frequencyBinCount;
                    dataArray = new Uint8Array(bufferLength);
                    source.connect(analyser);
                    visualizeAudio();
                    startButton.textContent = "Listening...";
                })
                .catch(err => {
                    console.error('Error accessing microphone:', err);
                    alert('Microphone access denied.');
                });
        });

        function visualizeAudio() {
            requestAnimationFrame(visualizeAudio);
            analyser.getByteTimeDomainData(dataArray);

            // Calculate amplitude and smooth it
            let amplitude = Math.max(...dataArray);
            smoothedAmplitude = smoothedAmplitude * 0.9 + amplitude * 0.1;  // Smoothing the signal
            audioLevelDisplay.textContent = smoothedAmplitude;

            // Adapt threshold dynamically based on the average amplitude
            threshold = smoothedAmplitude * 1.2;

            // Beat detection based on adaptive threshold
            let currentTime = audioContext.currentTime;
            if (smoothedAmplitude > threshold) {  // Beat detected when amplitude exceeds threshold
                if (currentTime - previousTime > 0.3) {  // Prevent detecting too many beats close together
                    beatTimestamps.push(currentTime);
                    previousTime = currentTime;
                }

                // Calculate BPM based on time between beats
                if (beatTimestamps.length > 1) {
                    const intervals = beatTimestamps.slice(-5).map((t, i, arr) => t - (arr[i - 1] || t));
                    const avgInterval = intervals.reduce((sum, val) => sum + val, 0) / intervals.length;
                    const bpm = 60 / avgInterval;
                    const rpm = bpm / 2;

                    bpmDisplay.textContent = Math.round(bpm);
                    rpmDisplay.textContent = rpm.toFixed(1);
                }
            }
        }
    </script>
</body>
</html>
